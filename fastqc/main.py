#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
  Copyright (c) 2021, ICGC ARGO

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to deal
  in the Software without restriction, including without limitation the rights
  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
  copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in all
  copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
  SOFTWARE.

  Authors:
    Linda Xiang
"""

import os
import sys
import argparse
import subprocess
from multiprocessing import cpu_count
from zipfile import ZipFile
import json
from glob import glob
import tarfile
import io
import hashlib
import re

def run_cmd(cmd):
    proc = subprocess.Popen(
                cmd,
                shell=True,
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )
    stdout, stderr = proc.communicate()

    return (
        stdout.decode("utf-8").strip(),
        stderr.decode("utf-8").strip(),
        proc.returncode
    )

def get_tool_version(toolname):
    get_tool_version_cmd = f"{toolname} --version | grep -i '^{toolname}'"
    stdout, stderr, returncode = run_cmd(get_tool_version_cmd)
    if returncode:
        sys.exit(f"Error: unable to get version info for {toolname}.\nStdout: {stdout}\nStderr: {stderr}\n")

    return stdout.strip().split(' ')[-1].strip('v')

def prep_qc_metrics(name, output_dir, tool_ver):
    qc_metrics = {
        'tool': {
            'name': 'FastQC',
            'version': tool_ver
        },
        'metrics': [],
        'description': 'High level sequencing reads QC metrics generated by FastQC.'
    }

    for fastqc_zip in sorted(glob(os.path.join(output_dir, "*_fastqc.zip"))):
      metric = {"read_group_id": name}
      fastqc_summary = os.path.join(os.path.basename(fastqc_zip).rstrip('.zip'), "summary.txt")
      fastqc_data = os.path.join(os.path.basename(fastqc_zip).rstrip('.zip'), "fastqc_data.txt")
      with ZipFile(fastqc_zip) as myzip:
        with myzip.open(fastqc_summary) as sumfile:
          with io.TextIOWrapper(sumfile, encoding="utf-8") as sumtext:
            for line in sumtext:
              cols = line.rstrip().split('\t')
              metric.update({
                cols[1].lower().replace(" ", "_"): cols[0]
              })
            metric.update({"file_name": cols[2]})
        # get matrics from data file
        with myzip.open(fastqc_data) as datafile:
          with io.TextIOWrapper(datafile, encoding="utf-8") as datatext:
            for line in datatext:
               if line.startswith("Total Sequences"):
                 metric.update({"total_sequences": line.strip().split("\t")[1]})
               elif line.startswith("Sequences flagged as poor quality"):
                 metric.update({"poor_sequences": line.strip().split("\t")[1]})
               elif line.startswith("Sequence length"):
                 metric.update({"average_sequence_length": line.strip().split("\t")[1]})
               elif line.startswith("#Total Deduplicated Percentage"):
                 metric.update({"duplicated_percentage": line.strip().split("\t")[1]})
               elif line.startswith("%GC"):
                 metric.update({"%GC": line.strip().split("\t")[1]})
        # End of chunk
      qc_metrics['metrics'].append(metric)

    qc_metrics_file = 'qc_metrics.json'
    with open(qc_metrics_file, "w") as j:
        j.write(json.dumps(qc_metrics, indent=2))

    return qc_metrics_file

def prepare_tarball(name, qc_metrics, output_dir):

    files_to_tar = [qc_metrics]
    for f in sorted(glob(output_dir+'/*')):
      files_to_tar.append(f)

    tarfile_name = f"{name}.fastqc.tgz"
    with tarfile.open(tarfile_name, "w:gz") as tar:
      for f in files_to_tar:
        tar.add(f, arcname=os.path.basename(f))


def main():
    """
    Python implementation of tool: fastqc
    """

    parser = argparse.ArgumentParser(description='Tool: fastqc')
    parser.add_argument('-s', '--seq', type=str, nargs="+", help='Input seq', required=True)
    parser.add_argument('-n', '--rg_id', type=str, help='Read_group name', required=True)
    parser.add_argument('-t', '--threads', type=int, default=cpu_count(), help='Number of threads')
    args = parser.parse_args()

    for fn in args.seq: 
      if not os.path.isfile(fn):
        sys.exit('Error: specified seq file %s does not exist or is not accessible!' % fn)

    # get tool version info
    tool_ver = get_tool_version('fastqc')

    output_dir = 'output'
    if not os.path.exists(output_dir):
      os.makedirs(output_dir)

    # run fastqc
    fastqc_args = [
        '-q',
        '-t', str(args.threads),
        '-o', output_dir
    ]

    cmd = ['fastqc'] + fastqc_args + args.seq
    stdout, stderr, returncode = run_cmd(" ".join(cmd))
    if returncode:
        sys.exit(f"Error: 'fastqc' failed.\nStdout: {stdout}\nStderr: {stderr}\n")

    
    # parse fastqc output and put it in qc_metrics.json
    qc_metrics_file = prep_qc_metrics(args.rg_id, output_dir, tool_ver)

    # in case the rg_id contains filename not friendly characters
    friendly_rgid = "".join([ c if re.match(r"[a-zA-Z0-9\.\-_]", c) else "_" for c in args.rg_id ])
    # calculate md5 and add it in the logfile name to avoid name colision
    md5sum = hashlib.md5((args.rg_id).encode('utf-8')).hexdigest()
    prefix_name = '.'.join([friendly_rgid, md5sum])

    # prepare tarball to include output files and qc_metrics.json
    prepare_tarball(prefix_name, qc_metrics_file, output_dir)

if __name__ == "__main__":
    main()
